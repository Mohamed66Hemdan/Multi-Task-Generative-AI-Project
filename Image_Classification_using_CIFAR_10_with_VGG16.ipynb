{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, array_to_img"
      ],
      "metadata": {
        "id": "qfh4yjOsZn7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train_full, y_train_full), (x_test_full, y_test_full) = cifar10.load_data()\n",
        "\n",
        "x_train, y_train = x_train_full[:1000], y_train_full[:1000]\n",
        "x_test, y_test = x_test_full[:200], y_test_full[:200]\n",
        "\n",
        "# Resize to 224x224 and preprocess using VGG16 preprocess_input\n",
        "def resize_and_preprocess(images):\n",
        "    resized = np.zeros((images.shape[0], 224, 224, 3), dtype=np.float32)\n",
        "    for i in range(images.shape[0]):\n",
        "        img = array_to_img(images[i])\n",
        "        img = img.resize((224, 224))\n",
        "        resized[i] = img_to_array(img)\n",
        "    return preprocess_input(resized)\n",
        "\n",
        "x_train = resize_and_preprocess(x_train)\n",
        "x_test = resize_and_preprocess(x_test)\n",
        "\n",
        "y_train_cat = to_categorical(y_train, 10)\n",
        "y_test_cat = to_categorical(y_test, 10)"
      ],
      "metadata": {
        "id": "Le9GzTSoZpSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "predictions = Dense(10, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train_cat, epochs=5, batch_size=32, validation_data=(x_test, y_test_cat))\n",
        "\n",
        "loss, accuracy = model.evaluate(x_test, y_test_cat)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QmTPTICY9KD",
        "outputId": "bc47243c-2b3a-4df2-bd43-3307d5c48e69"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 268ms/step - accuracy: 0.1061 - loss: 4.9824 - val_accuracy: 0.1650 - val_loss: 3.2821\n",
            "Epoch 2/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 217ms/step - accuracy: 0.2244 - loss: 2.9365 - val_accuracy: 0.2850 - val_loss: 2.3692\n",
            "Epoch 3/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 220ms/step - accuracy: 0.3523 - loss: 2.0861 - val_accuracy: 0.3650 - val_loss: 1.9932\n",
            "Epoch 4/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 224ms/step - accuracy: 0.4580 - loss: 1.7113 - val_accuracy: 0.4500 - val_loss: 1.7562\n",
            "Epoch 5/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 221ms/step - accuracy: 0.5388 - loss: 1.3991 - val_accuracy: 0.4900 - val_loss: 1.6036\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 167ms/step - accuracy: 0.4828 - loss: 1.6125\n",
            "Test Accuracy: 0.4900\n"
          ]
        }
      ]
    }
  ]
}
